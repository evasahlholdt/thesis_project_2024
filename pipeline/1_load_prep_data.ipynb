{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load and prepare data from MNE-Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Discard 6 subjects: 88, 89, 92, 100, 104, 106 (see https://www.sciencedirect.com/science/article/pii/S2352340924001525#sec0004)\n",
    "subjects = set(range(1, 104))\n",
    "subjects = list(sorted(subjects - {88, 89, 92, 100, 104, 106}))\n",
    "\n",
    "# Define MI left/right hand runs\n",
    "runs = [4, 8, 12]\n",
    "\n",
    "path = ## PATH TO STORE DATASET ##\n",
    "\n",
    "raw_fnames_all = []\n",
    "for subject in subjects:\n",
    "    raw_fnames = eegbci.load_data(subject, runs, path=path)\n",
    "    raw_fnames_all.extend(raw_fnames)\n",
    "\n",
    "raws = [read_raw_edf(f, preload=False) for f in raw_fnames_all]\n",
    "for raw in raws:    \n",
    "    raw.crop(tmax=122.9937) # Crop to standard recording length for run (19680 measurements)\n",
    "\n",
    "raw = concatenate_raws(raws)\n",
    "\n",
    "df_raw = raw.to_data_frame()\n",
    "\n",
    "print(f\"Shape of df_raw:\", df_raw.shape) \n",
    "print(f\"Expected length:\", 19680 * 3 * 103) #Run length * number of runs pr subject * number of subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotation/task labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "['rest' 'right' 'left']\n",
      "(6081120, 67)\n"
     ]
    }
   ],
   "source": [
    "events = mne.events_from_annotations(raw)\n",
    "events_df = pd.DataFrame(events[0], columns = [\"time_index\", \"X\", \"annotation\"])\n",
    "event_df = events_df.drop('X', axis = 1)\n",
    "\n",
    "# 1 = T0 (rest); 2 = T1 (left); 3 = T2 (right)\n",
    "\n",
    "df_raw = df_raw.reset_index().rename(columns={'index': 'time_index'})\n",
    "df = pd.merge(df_raw, event_df[['time_index', 'annotation']], on='time_index', how='left').fillna(method='ffill')\n",
    "df['annotation'] = df['annotation'].replace({1: 'rest', 2: 'left', 3: 'right'})\n",
    "\n",
    "print(df['annotation'].unique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add subject_ID and run as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "run_1    2027040\n",
      "run_2    2027040\n",
      "run_3    2027040\n",
      "Name: run, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['subject_ID'] = ['S' + str(id) for id in ((np.arange(len(df)) // (19680 * 3)) + 1)]\n",
    "\n",
    "run_labels = list(np.repeat(['run_1', 'run_2', 'run_3'], 19680))\n",
    "df['run'] = np.tile(run_labels, 103)[:len(df)]\n",
    "\n",
    "print(df['subject_ID'].nunique())\n",
    "print(df['run'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore consistency in trial length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_annotation'] = df['annotation'].shift()\n",
    "changes = df[df['annotation'].ne(df['prev_annotation'])]\n",
    "\n",
    "lengths_of_changes = []\n",
    "\n",
    "prev_idx = None\n",
    "for idx, row in changes.iterrows():\n",
    "    if prev_idx is not None:\n",
    "        change_length = idx - prev_idx\n",
    "        lengths_of_changes.append(change_length)\n",
    "    prev_idx = idx\n",
    "\n",
    "df = df.drop(columns=\"prev_annotation\")\n",
    "print(f\"Number of changes:\", len(lengths_of_changes))\n",
    "print(f\"Target number of changes:\", 103*3*30-1) #103 subjects, 3 runs, 30 trials, - 1 for end\n",
    "print(f\"Length of trials and count:\", np.unique(lengths_of_changes, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate/remove samples\n",
    "\n",
    "Because trial length is not consistent, we remove shorter sequences and truncate longer sequences to fit a standard length (most frequently observed: 656 obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, column):\n",
    "    splits = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        if df[column].iloc[i] != df[column].iloc[start_idx]:\n",
    "            splits.append(df.iloc[start_idx:i])\n",
    "            start_idx = i\n",
    "\n",
    "    splits.append(df.iloc[start_idx:])\n",
    "    \n",
    "    return splits\n",
    "\n",
    "\n",
    "def filter_and_truncate_splits(splits, min_length=656, max_length=656):\n",
    "    filtered_splits = []\n",
    "    \n",
    "    for split in splits:\n",
    "        if len(split) >= min_length:\n",
    "            if len(split) > max_length:\n",
    "                split = split.iloc[:max_length]\n",
    "            filtered_splits.append(split)\n",
    "    \n",
    "    return filtered_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['subject_ID'].unique()\n",
    "runs = df['run'].unique()\n",
    "final_filtered_splits = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for run in runs:\n",
    "        sub_df = df[(df[\"subject_ID\"] == subject) & (df[\"run\"] == run)]\n",
    "        splits = split_dataframe(sub_df, 'annotation')\n",
    "        filtered_splits = filter_and_truncate_splits(splits, min_length=656, max_length=656)\n",
    "        lengths = [len(s) for s in filtered_splits]\n",
    "        final_filtered_splits.extend(filtered_splits)\n",
    "\n",
    "df = pd.concat(final_filtered_splits).reset_index(drop=True)\n",
    "\n",
    "print(f\"Length of dataset:\", df.shape)\n",
    "print(f\"Target length of dataset:\", len(df) - (63*416+11*624+25*640) - (970*672-970*656 + 11*688-11*656))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/data_csv/df_MI.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNE_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
